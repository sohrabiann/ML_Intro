{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "370AKC5oUxsB"
   },
   "source": [
    "# Machine Learning Pipeline \n",
    "\n",
    "## Introduction\n",
    "In this script, I've implemented a machine learning pipeline to handle a binary classification problem. This involves data preprocessing, model training, and evaluation. The data consists of two types: normal and anomalous.\n",
    "\n",
    "## Libraries and Data Loading\n",
    "Firstly, I import necessary libraries:\n",
    "\n",
    "- `numpy` for numerical operations.\n",
    "- `pandas` for data manipulation.\n",
    "- `sklearn` for machine learning models and functions.\n",
    "- `matplotlib.pyplot` for visualization.\n",
    "\n",
    "I set a random seed using `np.random.seed(42)` for reproducibility. Then, I load two datasets: `normalData` and `anomalousData`, each containing features and a target variable.\n",
    "\n",
    "## Data Preprocessing\n",
    "The function `myTrainTestSplit` splits both datasets into training and testing sets. It first separates features (`X`) and labels (`y`), then applies `train_test_split` with a 70-30 split. Finally, it merges the normal and anomalous data to form combined training and testing sets.\n",
    "\n",
    "## Model Training Functions\n",
    "I define functions for training different models:\n",
    "\n",
    "1. **Decision Tree (`myDecisionTree`)**: Trains a basic decision tree classifier.\n",
    "2. **Bagging (`myBagging`)**: Implements a bagging classifier using decision trees as base estimators.\n",
    "3. **Random Forest (`myRandomForest`)**: Trains a random forest classifier.\n",
    "\n",
    "Each function fits the model to the training data and returns the trained model.\n",
    "\n",
    "## Feature Importance Visualization\n",
    "`plot_feature_importance` visualizes the importance of different features in a model, particularly useful for understanding random forests.\n",
    "\n",
    "## Model Evaluation\n",
    "The function `myEvaluateSupervisedModelPerformance` evaluates the performance of the supervised models (Decision Tree, Bagging, Random Forest) using metrics like recall, precision, and F1 score. It also prints the training time and confusion matrix for each model.\n",
    "\n",
    "## PCA with Random Forest Pipeline\n",
    "I also define `myPCARF`, which creates a pipeline combining PCA (Principal Component Analysis) for dimensionality reduction and a random forest classifier. This is an example of an unsupervised approach to feature extraction followed by supervised learning.\n",
    "\n",
    "## Unsupervised Model Evaluation\n",
    "Finally, `myEvaluateUnsupervisedModelPerformance` evaluates the PCA-Random Forest pipeline using the same metrics as the supervised models.\n",
    "\n",
    "## Summary\n",
    "This script demonstrates a comprehensive approach to a binary classification task, utilizing both supervised and unsupervised learning techniques, and emphasizing model evaluation and interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "45VAP00lUkc5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e9fI_lLV3MhP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "import time\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VYa70oGzXmbl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normal dataset: (76593, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "normalData = pd.read_csv('normal.csv')\n",
    "print(f'Shape of normal dataset: {normalData.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T2EbZ-FwYIGl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of anomalous dataset: (2599, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "anomalousData = pd.read_csv('anomalous.csv')\n",
    "print(f'Shape of anomalous dataset: {anomalousData.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7kC7gNWGQbC1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def myTrainTestSplit(normalData, anomalousData):\n",
    "    \n",
    "    X_normal = normalData.iloc[:, :-1]\n",
    "    y_normal = normalData.iloc[:, -1]\n",
    "\n",
    "    X_anomalous = anomalousData.iloc[:, :-1]\n",
    "    y_anomalous = anomalousData.iloc[:, -1]\n",
    "\n",
    "  \n",
    "    X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(X_normal, y_normal, test_size=0.3, random_state=42)\n",
    "    X_train_anomalous, X_test_anomalous, y_train_anomalous, y_test_anomalous = train_test_split(X_anomalous, y_anomalous, test_size=0.3, random_state=42)\n",
    "\n",
    "    \n",
    "    X_train = pd.concat([X_train_normal, X_train_anomalous])\n",
    "    X_test = pd.concat([X_test_normal, X_test_anomalous])\n",
    "    y_train = pd.concat([y_train_normal, y_train_anomalous])\n",
    "    y_test = pd.concat([y_test_normal, y_test_anomalous])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def myDecisionTree(X_train, y_train):\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def myBagging(X_train, y_train):\n",
    "    \n",
    "    base_clf = DecisionTreeClassifier()\n",
    "    bagging_clf = BaggingClassifier(base_estimator=base_clf, n_estimators=10, random_state=42)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "   \n",
    "    return bagging_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Rdw3xDzGZdAb"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def myRandomForest(X_train, y_train):\n",
    "   \n",
    "    clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot_feature_importance(model, feature_names):\n",
    "   \n",
    "    importances = model.feature_importances_\n",
    "\n",
    "  \n",
    "    indices = np.argsort(importances)\n",
    "\n",
    "    # Plot the feature importances\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def myEvaluateSupervisedModelPerformance(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    recalls = np.zeros(3)\n",
    "    precisions = np.zeros(3)\n",
    "    f1_scores = np.zeros(3)\n",
    "\n",
    "    # List of model functions\n",
    "    model_funcs = [myDecisionTree, myBagging, myRandomForest]\n",
    "\n",
    "    for i, model_func in enumerate(model_funcs):\n",
    "       \n",
    "        start = time.time()\n",
    "        model = model_func(X_train, y_train)\n",
    "        end = time.time()\n",
    "        print(f'Training time for model {i+1}: {end - start} seconds')\n",
    "\n",
    "       \n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        recalls[i] = recall_score(y_test, y_pred)\n",
    "        precisions[i] = precision_score(y_test, y_pred)\n",
    "        f1_scores[i] = f1_score(y_test, y_pred)\n",
    "\n",
    "        \n",
    "        print(f'Confusion matrix for model {i+1}:\\n{confusion_matrix(y_test, y_pred)}\\n')\n",
    "\n",
    "   \n",
    "    print(f'Recalls: {recalls}')\n",
    "    print(f'Precisions: {precisions}')\n",
    "    print(f'F1 scores: {f1_scores}')\n",
    "\n",
    "    return recalls, precisions, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def myPCARF(X_train, y_train):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('pca', PCA(n_components=2)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42))\n",
    "    ])\n",
    "\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldPs5xBRa7Q5",
    "outputId": "223857e9-24a7-4889-b543-1300726f575f"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def myEvaluateUnsupervisedModelPerformance(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    recalls = np.zeros(1)\n",
    "    precisions = np.zeros(1)\n",
    "    f1_scores = np.zeros(1)\n",
    "\n",
    " \n",
    "    start = time.time()\n",
    "    model = myPCARF(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(f'Training time for model: {end - start} seconds')\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    recalls[0] = recall_score(y_test, y_pred)\n",
    "    precisions[0] = precision_score(y_test, y_pred)\n",
    "    f1_scores[0] = f1_score(y_test, y_pred)\n",
    "\n",
    "   \n",
    "    print(f'Confusion matrix for model:\\n{confusion_matrix(y_test, y_pred)}\\n')\n",
    "\n",
    "    \n",
    "    print(f'Recalls: {recalls}')\n",
    "    print(f'Precisions: {precisions}')\n",
    "    print(f'F1 scores: {f1_scores}')\n",
    "\n",
    "    return recalls, precisions, f1_scores"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3YmD_jy2VkV5",
    "ttLtyLi1b0IE",
    "tLUT1nMwdYKw"
   ],
   "name": "ECE9309_9039_Assignment2_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
